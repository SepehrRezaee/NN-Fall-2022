{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### **Sepehr Rezaee - 99242067**"
      ],
      "metadata": {
        "id": "0Wv7tsONWGLY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Import Requirements**"
      ],
      "metadata": {
        "id": "XslB9QedY4Pn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import random\n",
        "import argparse\n",
        "import numpy as np\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.utils.data as data\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "\n",
        "%matplotlib inline\n"
      ],
      "metadata": {
        "id": "HTgTrPCPY3nL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Download and Load the dataset**"
      ],
      "metadata": {
        "id": "2AdMyKeMY-3R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download and load the CIFAR10 dataset\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "\n",
        "def get_my_dataset(size=100, flag=True):\n",
        "    indexes = random.sample(range(0, 5000), size)\n",
        "    divsure = 4\n",
        "    group1 = indexes[:size//divsure]\n",
        "    group2 = indexes[size//divsure:]\n",
        "    dataset = torchvision.datasets.CIFAR10(root='./data', train=flag,\n",
        "                                    download=True, transform=transform)\n",
        "    pair_indexes = [(i, j) for i in group1 for j in group2]\n",
        "\n",
        "    def get_item(idx):\n",
        "        index1, index2 = pair_indexes[idx]\n",
        "        img1 = dataset[index1][0]\n",
        "        img2 = dataset[index2][0]\n",
        "        result = img1 + img2\n",
        "        result = result / 2\n",
        "        return result, (img1, img2)\n",
        "\n",
        "    return len(pair_indexes), get_item\n",
        "\n",
        "\n",
        "# Create a custom dataset object that wraps the get_item function\n",
        "class MyDatasetObject:\n",
        "    def __init__(self, length, get_item):\n",
        "        self.length = length\n",
        "        self.get_item = get_item\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.length\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.get_item(idx)"
      ],
      "metadata": {
        "id": "wsYw4x94ZKlw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Define the encoder and decoder and autoencoder networks**"
      ],
      "metadata": {
        "id": "rD94r57rZNsT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class conv_block(nn.Module):\n",
        "    def __init__(self, in_c, out_c):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(in_c, out_c, kernel_size=3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(out_c)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(out_c, out_c, kernel_size=3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(out_c)\n",
        "\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        x = self.conv1(inputs)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "\n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x)\n",
        "        x = self.relu(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "# Encoder\n",
        "class encoder_block(nn.Module):\n",
        "    def __init__(self, in_c, out_c):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv = conv_block(in_c, out_c)\n",
        "        self.pool = nn.MaxPool2d((2, 2))\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        x = self.conv(inputs)\n",
        "        p = self.pool(x)\n",
        "\n",
        "        return x, p\n",
        "\n",
        "# Decoder\n",
        "class decoder_block(nn.Module):\n",
        "    def __init__(self, in_c, out_c):\n",
        "        super().__init__()\n",
        "\n",
        "        self.up = nn.ConvTranspose2d(in_c, out_c, kernel_size=2, stride=2, padding=0)\n",
        "        self.conv = conv_block(out_c+out_c, out_c)\n",
        "\n",
        "    def forward(self, inputs, skip):\n",
        "        x = self.up(inputs)\n",
        "        x = torch.cat([x, skip], axis=1)\n",
        "        x = self.conv(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "class build_unet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "\n",
        "        self.e1 = encoder_block(3, 64)\n",
        "        self.e2 = encoder_block(64, 128)\n",
        "        self.e3 = encoder_block(128, 256)\n",
        "        self.e4 = encoder_block(256, 512)\n",
        "\n",
        "\n",
        "        self.b = conv_block(512, 1024)\n",
        "\n",
        "\n",
        "        self.d1 = decoder_block(1024, 512)\n",
        "        self.d2 = decoder_block(512, 256)\n",
        "        self.d3 = decoder_block(256, 128)\n",
        "        self.d4 = decoder_block(128, 64)\n",
        "\n",
        "        self.d11 = decoder_block(1024, 512)\n",
        "        self.d22 = decoder_block(512, 256)\n",
        "        self.d33 = decoder_block(256, 128)\n",
        "        self.d44 = decoder_block(128, 64)\n",
        "\n",
        "\n",
        "        self.outputs = nn.Conv2d(64, 3, kernel_size=1, padding=0)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "\n",
        "        s1, p1 = self.e1(inputs)\n",
        "        s2, p2 = self.e2(p1)\n",
        "        s3, p3 = self.e3(p2)\n",
        "        s4, p4 = self.e4(p3)\n",
        "\n",
        "\n",
        "        b = self.b(p4)\n",
        "\n",
        "\n",
        "        d1 = self.d1(b, s4)\n",
        "        d2 = self.d2(d1, s3)\n",
        "        d3 = self.d3(d2, s2)\n",
        "        d4 = self.d4(d3, s1)\n",
        "\n",
        "        d11 = self.d11(b, s4)\n",
        "        d22 = self.d22(d11, s3)\n",
        "        d33 = self.d33(d22, s2)\n",
        "        d44 = self.d44(d33, s1)\n",
        "\n",
        "\n",
        "        outputs1 = self.outputs(d4)\n",
        "        outputs2 = self.outputs(d44)\n",
        "\n",
        "        return outputs1, outputs2"
      ],
      "metadata": {
        "id": "gT6KzmVmZV_L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the U-Net model\n",
        "model = build_unet()\n",
        "\n",
        "# Define the loss function and optimizer\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "Mhd4YC9cZbNS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "length, get_item = get_my_dataset()\n",
        "\n",
        "dataset = MyDatasetObject(length, get_item)\n",
        "\n",
        "# Create a DataLoader from the dataset\n",
        "data_loader = DataLoader(dataset, batch_size=32, shuffle=True, num_workers=2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YoFMHZV11I4F",
        "outputId": "9f315681-9ba3-4e59-ed53-cb59be474405"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Train the autoencoder**"
      ],
      "metadata": {
        "id": "lcS3xUxUZhxo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (inputs, (img1, img2)) in enumerate(data_loader, 0):\n",
        "        outputs1, outputs2 = model(inputs)\n",
        "        loss1 = criterion(outputs1, img1)\n",
        "        loss2 = criterion(outputs2, img2)\n",
        "        loss = (loss1 + loss2) / 2\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        print('.',end='',flush=True)\n",
        "\n",
        "    print('\\r',end='')\n",
        "    print(f'Epoch : {epoch+1}/{num_epochs}, Loss : {loss.data}')"
      ],
      "metadata": {
        "id": "0IYFn56TyrPt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35b26138-9842-42ab-f37a-2e3c6fbc64a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 1/10, Loss : 0.13804861903190613\n",
            "Epoch : 2/10, Loss : 0.10240800678730011\n",
            "Epoch : 3/10, Loss : 0.06953547894954681\n",
            "Epoch : 4/10, Loss : 0.05312111973762512\n",
            "Epoch : 5/10, Loss : 0.04707729071378708\n",
            "Epoch : 6/10, Loss : 0.035461291670799255\n",
            "Epoch : 7/10, Loss : 0.02903291955590248\n",
            "Epoch : 8/10, Loss : 0.025823332369327545\n",
            "Epoch : 9/10, Loss : 0.01703120768070221\n",
            "Epoch : 10/10, Loss : 0.01638597995042801\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Test the U-Net model**"
      ],
      "metadata": {
        "id": "wp0ToxSuR_r3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "length, get_item = get_my_dataset()\n",
        "\n",
        "dataset = MyDatasetObject(length, get_item)\n",
        "\n",
        "# Create a DataLoader from the dataset\n",
        "test_data_loader = DataLoader(dataset, batch_size=16, shuffle=True, num_workers=2)\n"
      ],
      "metadata": {
        "id": "PMqQC-zV10Pf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49718286-0b02-4657-9c8d-b706088573a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i, (input_batch, (output_batch1, output_batch2)) in enumerate(test_data_loader, 0):\n",
        "    # Compute the mean image\n",
        "    mean_image = (output_batch1 + output_batch2) / 2\n",
        "\n",
        "    # Display the mean image\n",
        "    print(\"mean image: \")\n",
        "    mean_image_np = mean_image[0].cpu().detach().numpy()\n",
        "    plt.imshow(np.transpose(mean_image_np, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "    # Display image 1\n",
        "    print(\"image 1: \")\n",
        "    image1_np = output_batch1[0].cpu().detach().numpy()\n",
        "    plt.imshow(np.transpose(image1_np, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "    # Display image 2\n",
        "    print(\"image 2: \")\n",
        "    image2_np = output_batch2[0].cpu().detach().numpy()\n",
        "    plt.imshow(np.transpose(image2_np, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "\n",
        "    # Predict image 1 and image 2\n",
        "    predict1 = model(input_batch)[0][1]\n",
        "    predict2 = model(input_batch)[0][1]\n",
        "\n",
        "    # Display the predicted images\n",
        "    print(\"predicted image 1: \")\n",
        "    predict1_np = predict1.cpu().detach().numpy()\n",
        "    plt.imshow(np.transpose(predict1_np, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "    print(\"predicted image 2: \")\n",
        "    predict2_np = predict2.cpu().detach().numpy()\n",
        "    plt.imshow(np.transpose(predict2_np, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "    # fig, axs = plt.subplots(2, 2)\n",
        "    # axs[1, 0].imshow(np.transpose(image1_np, (1, 2, 0)))\n",
        "    # axs[1, 1].imshow(np.transpose(image2_np, (1, 2, 0)))\n",
        "    # axs[0, 0].imshow(np.transpose(predict1_np, (1, 2, 0)))\n",
        "    # axs[0, 1].imshow(np.transpose(predict2_np, (1, 2, 0)))\n",
        "\n",
        "    break\n",
        "\n"
      ],
      "metadata": {
        "id": "N7DWIEE7gIep",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "19e02461-c55d-4387-d654-432b4045065b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 4 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Save the model parametrs**"
      ],
      "metadata": {
        "id": "58bB8X0a1-oU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if not os.path.exists('./weights'):\n",
        "    os.mkdir('./weights')\n",
        "torch.save(model.state_dict(), \"./weights/autoencoder.pkl\")"
      ],
      "metadata": {
        "id": "i5e5vN1plHmI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VkZbLdbI9B3Q"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}